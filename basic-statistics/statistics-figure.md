# Statistics Figure

{% tabs %}
{% tab title="Variance" %}
## Simple Explanation

It is an index of linearity. Compared with covariance, it is unit free, and more intuitive to understand.

$$\frac{\operatorname{Cov}(a, b)}{\sigma_{a} \sigma_{b}}$$ 

## Assumption, Pros, Cons

## Strucuture, Visualization

## Application
{% endtab %}

{% tab title="Covariance" %}
## Simple Explanation:

* It gives an indication of how far one variable is from its mean when we observe another variable a certain distance from its mean. In other words, it says how much \(and in which direction\) y moves when x moves.
{% endtab %}

{% tab title="Correlation" %}

{% endtab %}
{% endtabs %}

* $$R^2$$ : the goodness of fit
* **Kurtosis:** is a statistical measure that defines how heavily the tails of a distribution differ from the tails of a normal distribution. In other words, **kurtosis** identifies whether the tails of a given distribution contain extreme values.
* **skewness:** is a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean. The **skewness** value can be positive, zero, negative, or undefined

